#!/bin/bash
# Job name
#PBS -N pinn_treino_batch

# Output and error files
#PBS -o logs/saida.out
#PBS -e logs/saida.err

# Walltime (hh:mm:ss)
#PBS -l walltime=60:00:00

# Nodes and cores per node
#PBS -l nodes=compute-1-0:ppn=1

# Change to submission directory
cd $PBS_O_WORKDIR

# List nodes allocated
cat $PBS_NODEFILE

# Clean previous logs
rm -f logs/saida.* mpi_log*

# Load CUDA libraries
export LD_LIBRARY_PATH=/home/yan/MonoBatch/monoalg_deploy_server:/usr/local/cuda-12.3/targets/x86_64-linux/lib/:$LD_LIBRARY_PATH

# Load user conda (your installation)
export PATH=/home/yan/.conda/bin:$PATH


# Display GPU information
gpu_count=$(nvidia-smi -L | wc -l)
for (( i=0; i<gpu_count; i++ )); do
    gpu_info=$(nvidia-smi -L | sed -n "$((i+1))p")
    echo "$gpu_info"
    
    mig_count=$(nvidia-smi -i $i --query-gpu=mig.mode.current --format=csv,noheader | grep -c Enabled)
    
    if [ "$mig_count" -gt 0 ]; then
        nvidia-smi -i $i --query-compute-apps=uuid --format=csv,noheader,nounits | while IFS= read -r mig_uuid; do
            echo "  MIG: $mig_uuid"
        done
    else
        echo "  No MIG instances found."
    fi
done

# Check GPUs are visible
nvidia-smi

# Launch MPI Python training
time mpiexec --hostfile $PBS_NODEFILE /home/yan/.conda/envs/ep_emulator/bin/python src/EP/Generate_EP_Data_from_TT.py 100


time mpiexec --hostfile $PBS_NODEFILE /home/yan/.conda/envs/ep_emulator/bin/python src/analisys/qoi.py 
